= Red Hat Cluster Migration Workload

== Overview

This is a workload for Red Hat Cluster Migration Tool. It migrates applications from one OCP cluster to another.

Following section explains how to install this workload on your OCP cluster.

=== Deploy Mig Controller using the workload
[source,'bash']
----
ansible-playbook -i "bastion.${GUID}.${BASE_DOMAIN}", ./ansible/configs/ocp-workloads/ocp-workload.yml \
    -e"ansible_ssh_private_key_file=${ANSIBLE_USER_KEY_FILE}" \
    -e"ansible_user=${ANSIBLE_USER}" \
    -e"ocp_username=${OCP_USERNAME}" \
    -e"ocp_workload=ocp-workload-migration" \
    -e"silent=False" \
    -e"guid=${GUID}" \
    -e"ACTION=create" \
    -e"student_userid=${ANSIBLE_USER}" \
    -e @./secret.yaml <1> \
    -e @./workload.yaml <2>
----
<1> Add your `mig_aws_{access_key_id|secret_access_key}` variables in `secret.yml`
<2> All variables required by the workload go in this file

`mig_mode` variable decides whether to run the controller using CLI or UI.

To run using UI, you need to deploy `ocp-workload-mig-ui` along with this workload.   

==== Variables

|===
| Variable | Default Value | Description | Required 

| mig_migration_namespaces
| - 
| Namespaces to migrate (Comma separated string of namespaces e.g. 'sample1,sample2')
| Yes 

| mig_cluster_remote_address
| - 
| URL to connect to remote cluster
| Yes 

| mig_sa_token_remote
| - 
| Service Account token for remote cluster
| Yes

| mig_mode
| cli
| Run migration through cli or ui (Values : cli, ui)
| No

| mig_controller_version
| training-v1
| Migration controller version
| No

| mig_namespace
| mig
| Namespace for migration resources
| No

| mig_crd_{cluster\|migration\|plan\|storage\|registry}
| Default CRDs used by controller
| Migration controller CRDs
| No

| mig_storage_name
| migration-sample 
| Backend storage name
| No

| mig_storage_creds_name
| migstorage-creds 
| Backend storage credential name
| No

| mig_backup_storage_provider
| aws
| Backend store provider for backups
| No

| mig_volume_snapshot_provider
| aws
| Backend store provider for volume snapshots
| No

| mig_plan_name
| migplan-sample
| Name for migration plan
| No

| mig_migration_name
| migmigration-sample
| Name for migration 
| No

| mig_is_local_cluster_host
| false
| Is local cluster host?
| No

| mig_is_remote_cluster_host
| true
| Is remote cluster host?
| No

| mig_quiesce_pods
| false
| Quiesce pods or not 
| No

| mig_sa_token_remote_name
| sa-token-remote
| Name for SA token resource
| No

| mig_cleanup_namespace
| false
| Clean the namespace when removing workload?
| No
|===


==== Backup Storage Locations

Migration controller uses AWS S3 as default backup location. You can change the backup location provider by overriding `mig_backup_storage_provider`.

Supported backup storage providers are - aws, noobaa. (Please note that `noobaa` is not fully tested)

Volume snapshot locations are not supported with NooBaa. Please use S3 for volume snapshots.

==== AWS 

|===
| Variable | Default | Description | Required

| mig_aws_bucket 
| -
| S3 backup bucket
| Yes

| mig_aws_region 
| - 
| AWS Region
| Yes

| mig_aws_access_key_id
| - 
| AWS Access Key Id 
| Yes

| mig_aws_secret_access_key
| - 
| AWS Secret Access Key
| Yes
|===

==== NooBaa 

|===
| Variable | Default | Description | Required

| mig_noobaa_bucket 
| -
| NooBaa backup bucket
| Yes

| mig_noobaa_s3_url
| -
| NooBaa service endpoint
| Yes

| mig_aws_access_key_id
| - 
| NooBaa access key id 
| Yes

| mig_aws_secret_access_key
| - 
| NooBaa secret access key
| Yes

| mig_noobaa_region 
| noobaa
| NooBaa region
| No
|===

=== Delete Velero workload

[source,'bash']
----
ansible-playbook -i "bastion.${GUID}.${BASE_DOMAIN}", ./ansible/configs/ocp-workloads/ocp-workload.yml \
    -e"ansible_ssh_private_key_file=${ANSIBLE_USER_KEY_FILE}" \
    -e"ansible_user=${ANSIBLE_USER}" \
    -e"ocp_username=${OCP_USERNAME}" \
    -e"ocp_workload=ocp-workload-velero" \
    -e"silent=False" \
    -e"guid=${GUID}" \
    -e"ACTION=delete" \
    -e"student_userid=${ANSIBLE_USER}" \
    -e"cleanup_namespace=false" \ <1>
    -e @./secret.yaml \
    -e @./workload.yaml
----
<1> Optionally, set this to `true` to delete the namespace after deleting workload. 

